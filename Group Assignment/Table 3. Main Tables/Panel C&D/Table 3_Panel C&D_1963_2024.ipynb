{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvqAO--yBpgc"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "# ======================================================================\n",
        "#   Cooper, Gulen & Schill (2008) — Table III (1963–2024 전체 버전)\n",
        "#   Panel C / D, Fama–MacBeth + Table 이미지/CSV 출력\n",
        "# ======================================================================\n",
        "\n",
        "!pip install wrds pandas numpy statsmodels tqdm --quiet\n",
        "\n",
        "import wrds\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "\n",
        "pd.set_option(\"display.max_columns\", 200)\n",
        "\n",
        "# ======================================================================\n",
        "# WRDS CONNECT\n",
        "# ======================================================================\n",
        "db = wrds.Connection()\n",
        "\n",
        "# ======================================================================\n",
        "# 샘플 기간 설정\n",
        "# ======================================================================\n",
        "START_FYEAR = 1962\n",
        "END_FYEAR   = 2023     # portyear = 2024까지 생성됨\n",
        "START_CRSP_DATE = '1962-01-01'\n",
        "END_CRSP_DATE   = '2024-12-31'\n",
        "PORTYEAR_START  = 1963\n",
        "PORTYEAR_END    = 2024\n",
        "\n",
        "# ======================================================================\n",
        "# 1. LOAD COMPUSTAT (1962–2023)\n",
        "# ======================================================================\n",
        "sql_comp = f\"\"\"\n",
        "    SELECT gvkey, datadate, fyear, at, sale, seq, ceq, txditc,\n",
        "           pstkrv, pstkl, pstk, ni, dlc, dltt, rect, act, che,\n",
        "           ppent, ap, lct, lt, dp, cusip\n",
        "    FROM comp.funda\n",
        "    WHERE indfmt='INDL'\n",
        "      AND datafmt='STD'\n",
        "      AND consol='C'\n",
        "      AND fyear BETWEEN {START_FYEAR} AND {END_FYEAR}\n",
        "\"\"\"\n",
        "comp = db.raw_sql(sql_comp, date_cols=[\"datadate\"])\n",
        "comp = comp.sort_values([\"gvkey\", \"fyear\"])\n",
        "\n",
        "# txditc missing 처리\n",
        "if \"txditc\" not in comp.columns:\n",
        "    comp[\"txditc\"] = 0\n",
        "\n",
        "# ========== Book Equity ==========\n",
        "comp[\"pstk_adj\"] = comp[\"pstkrv\"].fillna(comp[\"pstkl\"]).fillna(comp[\"pstk\"])\n",
        "comp[\"be\"] = comp[\"seq\"]\n",
        "\n",
        "mask = comp[\"be\"].isna()\n",
        "comp.loc[mask, \"be\"] = (\n",
        "    comp.loc[mask, \"ceq\"]\n",
        "    + comp.loc[mask, \"txditc\"].fillna(0)\n",
        "    - comp.loc[mask, \"pstk_adj\"].fillna(0)\n",
        ")\n",
        "comp = comp[comp[\"be\"] > 0]\n",
        "\n",
        "# BM lag\n",
        "comp[\"be_lag1\"] = comp.groupby(\"gvkey\")[\"be\"].shift(1)\n",
        "\n",
        "# ======================================================================\n",
        "# 1.1 LAG VARIABLES\n",
        "# ======================================================================\n",
        "lag_vars = [\"at\", \"sale\", \"be\", \"ppent\", \"act\", \"lct\"]\n",
        "for v in lag_vars:\n",
        "    for L in [1, 2, 5]:\n",
        "        comp[f\"{v}_lag{L}\"] = comp.groupby(\"gvkey\")[v].shift(L)\n",
        "\n",
        "# ======================================================================\n",
        "# 1.2 VARIABLE FORMULAS\n",
        "# ======================================================================\n",
        "comp[\"assetg\"]   = (comp[\"at\"]   - comp[\"at_lag1\"])   / comp[\"at_lag1\"]\n",
        "comp[\"l2assetg\"] = (comp[\"at_lag1\"] - comp[\"at_lag2\"]) / comp[\"at_lag2\"]\n",
        "\n",
        "comp[\"sysalesg\"] = (comp[\"sale\"] - comp[\"sale_lag5\"]) / comp[\"sale_lag5\"]\n",
        "comp[\"syassetg\"] = (comp[\"at\"]   - comp[\"at_lag5\"])   / comp[\"at_lag5\"]\n",
        "\n",
        "comp[\"ci\"] = (comp[\"ppent\"] - comp[\"ppent_lag1\"]) / comp[\"ppent_lag1\"]\n",
        "\n",
        "comp[\"noa\"]   = comp[\"at\"] - comp[\"che\"] - comp[\"dlc\"] - comp[\"dltt\"] - comp[\"ni\"]\n",
        "comp[\"noa_a\"] = comp[\"noa\"] / comp[\"at\"]\n",
        "\n",
        "comp[\"accruals\"] = (\n",
        "    (comp[\"act\"] - comp[\"act_lag1\"])\n",
        "    - (comp[\"lct\"] - comp[\"lct_lag1\"])\n",
        "    - comp[\"dp\"].fillna(0)\n",
        ") / comp[\"at\"]\n",
        "\n",
        "comp[\"portyear\"] = comp[\"fyear\"] + 1\n",
        "comp[\"cusip8\"]   = comp[\"cusip\"].str[:8]\n",
        "\n",
        "# ======================================================================\n",
        "# 2. CUSIP LINK → PERMNO (msenames만 사용)\n",
        "# ======================================================================\n",
        "sql_link = \"\"\"\n",
        "    SELECT permno, ncusip, namedt, nameendt\n",
        "    FROM crsp.msenames\n",
        "    WHERE ncusip IS NOT NULL\n",
        "\"\"\"\n",
        "msenames = db.raw_sql(sql_link, date_cols=[\"namedt\", \"nameendt\"])\n",
        "msenames[\"cusip8\"] = msenames[\"ncusip\"].str[:8]\n",
        "\n",
        "comp_linked = comp.merge(\n",
        "    msenames[[\"permno\", \"cusip8\", \"namedt\", \"nameendt\"]],\n",
        "    on=\"cusip8\", how=\"inner\"\n",
        ")\n",
        "\n",
        "comp_linked = comp_linked[\n",
        "    (comp_linked[\"datadate\"] >= comp_linked[\"namedt\"]) &\n",
        "    (comp_linked[\"datadate\"] <= comp_linked[\"nameendt\"])\n",
        "]\n",
        "\n",
        "# ======================================================================\n",
        "# 3. LOAD CRSP (1962–2024)\n",
        "# ======================================================================\n",
        "sql_msf = f\"\"\"\n",
        "    SELECT a.permno, a.date, a.ret, a.prc, a.shrout,\n",
        "           b.shrcd, b.exchcd\n",
        "    FROM crsp.msf a\n",
        "    LEFT JOIN crsp.msenames b\n",
        "         ON a.permno = b.permno\n",
        "        AND a.date BETWEEN b.namedt AND b.nameendt\n",
        "    WHERE a.date BETWEEN '{START_CRSP_DATE}' AND '{END_CRSP_DATE}'\n",
        "\"\"\"\n",
        "crsp = db.raw_sql(sql_msf, date_cols=[\"date\"])\n",
        "crsp[\"ret\"] = pd.to_numeric(crsp[\"ret\"], errors=\"coerce\")\n",
        "\n",
        "crsp = crsp[(crsp[\"shrcd\"].isin([10, 11])) & (crsp[\"exchcd\"].isin([1, 2, 3]))]\n",
        "\n",
        "# delisting return\n",
        "sql_dl = \"SELECT permno, dlret, dlstdt FROM crsp.msedelist\"\n",
        "dl = db.raw_sql(sql_dl, date_cols=[\"dlstdt\"])\n",
        "dl[\"dlret\"] = pd.to_numeric(dl[\"dlret\"], errors=\"coerce\").fillna(0)\n",
        "\n",
        "crsp = crsp.merge(\n",
        "    dl, left_on=[\"permno\", \"date\"], right_on=[\"permno\", \"dlstdt\"], how=\"left\"\n",
        ")\n",
        "\n",
        "crsp[\"dlret\"] = crsp[\"dlret\"].fillna(0)\n",
        "crsp[\"ret_adj\"] = (1 + crsp[\"ret\"]) * (1 + crsp[\"dlret\"]) - 1\n",
        "\n",
        "crsp[\"me\"]    = crsp[\"prc\"].abs() * crsp[\"shrout\"] / 1000\n",
        "crsp[\"year\"]  = crsp[\"date\"].dt.year\n",
        "crsp[\"month\"] = crsp[\"date\"].dt.month\n",
        "crsp[\"portyear\"] = np.where(crsp[\"month\"] >= 7, crsp[\"year\"], crsp[\"year\"] - 1)\n",
        "\n",
        "# ======================================================================\n",
        "# 4. JUNE ME / BHRET6 / BHRET36 / Annual Return\n",
        "# ======================================================================\n",
        "crsp_june = crsp[crsp[\"month\"] == 6][[\"permno\", \"year\", \"me\", \"exchcd\"]]\n",
        "crsp_june = crsp_june.rename(columns={\"year\": \"portyear\", \"me\": \"me_june\"})\n",
        "\n",
        "bh6 = (\n",
        "    crsp[crsp[\"month\"] <= 6]\n",
        "    .groupby([\"permno\", \"year\"])[\"ret_adj\"]\n",
        "    .apply(lambda x: np.prod(1 + x) - 1)\n",
        "    .reset_index()\n",
        "    .rename(columns={\"year\": \"portyear\", \"ret_adj\": \"bhret6\"})\n",
        ")\n",
        "\n",
        "crsp = crsp.sort_values([\"permno\", \"date\"])\n",
        "crsp[\"cum\"] = (1 + crsp[\"ret_adj\"]).groupby(crsp[\"permno\"]).cumprod()\n",
        "\n",
        "bh36 = crsp[crsp[\"month\"] == 6].copy()\n",
        "bh36[\"lag\"] = bh36.groupby(\"permno\")[\"cum\"].shift(36)\n",
        "bh36[\"bhret36\"] = bh36[\"cum\"] / bh36[\"lag\"] - 1\n",
        "bh36 = bh36[[\"permno\", \"year\", \"bhret36\"]].rename(columns={\"year\": \"portyear\"})\n",
        "\n",
        "ann = (\n",
        "    crsp.groupby([\"permno\", \"portyear\"])[\"ret_adj\"]\n",
        "    .apply(lambda x: np.prod(1 + x) - 1)\n",
        "    .reset_index()\n",
        "    .rename(columns={\"ret_adj\": \"ret_annual\"})\n",
        ")\n",
        "\n",
        "# ======================================================================\n",
        "# 5. MERGE ALL DATA\n",
        "# ======================================================================\n",
        "df = comp_linked.merge(crsp_june, on=[\"permno\", \"portyear\"], how=\"inner\")\n",
        "df = df.merge(bh6,  on=[\"permno\", \"portyear\"], how=\"left\")\n",
        "df = df.merge(bh36, on=[\"permno\", \"portyear\"], how=\"left\")\n",
        "df = df.merge(ann,  on=[\"permno\", \"portyear\"], how=\"inner\")\n",
        "\n",
        "df = df[(df[\"portyear\"] >= PORTYEAR_START) & (df[\"portyear\"] <= PORTYEAR_END)]\n",
        "\n",
        "df[\"bm\"] = df[\"be_lag1\"] / df[\"me_june\"]\n",
        "df[\"bm\"] = df[\"bm\"].replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "print(\"포트폴리오 연도 범위:\", df[\"portyear\"].min(), \"→\", df[\"portyear\"].max())\n",
        "\n",
        "# ======================================================================\n",
        "# 6. NYSE BREAKPOINTS\n",
        "# ======================================================================\n",
        "nyse_bp = (\n",
        "    df[df[\"exchcd\"] == 1]\n",
        "    .groupby(\"portyear\")[\"me_june\"]\n",
        "    .quantile([0.3, 0.7])\n",
        "    .unstack()\n",
        "    .rename(columns={0.3: \"bp30\", 0.7: \"bp70\"})\n",
        ")\n",
        "\n",
        "df = df.merge(nyse_bp, on=\"portyear\", how=\"left\")\n",
        "\n",
        "def size_group(row):\n",
        "    if pd.isna(row[\"me_june\"]):\n",
        "        return None\n",
        "    if row[\"me_june\"] <= row[\"bp30\"]:\n",
        "        return \"Small\"\n",
        "    if row[\"me_june\"] <= row[\"bp70\"]:\n",
        "        return \"Medium\"\n",
        "    return \"Large\"\n",
        "\n",
        "df[\"size_group\"] = df.apply(size_group, axis=1)\n",
        "\n",
        "dfC = df[df[\"size_group\"] == \"Medium\"].copy()\n",
        "dfD = df[df[\"size_group\"] == \"Large\"].copy()\n",
        "\n",
        "print(\"Medium obs:\", len(dfC), \" / Large obs:\", len(dfD))\n",
        "\n",
        "# ======================================================================\n",
        "# 7. WINSORIZATION\n",
        "# ======================================================================\n",
        "winsor_cols = [\n",
        "    \"assetg\",\"l2assetg\",\"bm\",\"me_june\",\"bhret6\",\"bhret36\",\n",
        "    \"sysalesg\",\"syassetg\",\"ci\",\"noa_a\",\"accruals\"\n",
        "]\n",
        "\n",
        "def winsorize(df, cols):\n",
        "    for c in cols:\n",
        "        q_low  = df[c].quantile(0.01)\n",
        "        q_high = df[c].quantile(0.99)\n",
        "        df[c] = df[c].clip(lower=q_low, upper=q_high)\n",
        "    return df\n",
        "\n",
        "dfC = winsorize(dfC, winsor_cols)\n",
        "dfD = winsorize(dfD, winsor_cols)\n",
        "\n",
        "# ======================================================================\n",
        "# 8. FAMA–MACBETH\n",
        "# ======================================================================\n",
        "def newey_west(betas, lag=1):\n",
        "    betas = np.asarray(betas)\n",
        "    X = betas - betas.mean(0)\n",
        "    T = betas.shape[0]\n",
        "    S = (X.T @ X) / T\n",
        "    for L in range(1, lag + 1):\n",
        "        w = 1 - L/(lag + 1)\n",
        "        Gamma = (X[L:].T @ X[:-L]) / T\n",
        "        S += w * (Gamma + Gamma.T)\n",
        "    return S\n",
        "\n",
        "def fama_macbeth(df, Xvars):\n",
        "    betas = []\n",
        "    for yr, g in df.groupby(\"portyear\"):\n",
        "        cols = Xvars + [\"ret_annual\"]\n",
        "        g2 = g[cols].astype(float).dropna()\n",
        "        if g2.shape[0] < len(Xvars) + 2:\n",
        "            continue\n",
        "        X = sm.add_constant(g2[Xvars].values, has_constant='add')\n",
        "        y = g2[\"ret_annual\"].values\n",
        "        m = sm.OLS(y, X).fit()\n",
        "        params = np.asarray(m.params)\n",
        "        if np.isnan(params).any():\n",
        "            continue\n",
        "        betas.append(params)\n",
        "\n",
        "    if len(betas) == 0:\n",
        "        K = len(Xvars) + 1\n",
        "        return np.full(K, np.nan), np.full(K, np.nan)\n",
        "\n",
        "    betas = np.vstack(betas)\n",
        "    beta_mean = betas.mean(0)\n",
        "    cov = newey_west(betas)\n",
        "    tstat = beta_mean / np.sqrt(np.diag(cov))\n",
        "    return beta_mean, tstat\n",
        "\n",
        "# ======================================================================\n",
        "# 9. MODEL VARIABLES\n",
        "# ======================================================================\n",
        "MODEL_VARS = {\n",
        "    \"M1\": [\"assetg\",\"bm\",\"me_june\",\"bhret6\",\"bhret36\"],\n",
        "    \"M2\": [\"assetg\",\"l2assetg\",\"bm\",\"me_june\",\"bhret6\",\"bhret36\"],\n",
        "    \"M3\": [\"assetg\",\"bm\",\"me_june\",\"bhret6\",\"bhret36\",\"sysalesg\"],\n",
        "    \"M4\": [\"assetg\",\"bm\",\"me_june\",\"bhret6\",\"bhret36\",\"ci\"],\n",
        "    \"M5\": [\"assetg\",\"bm\",\"me_june\",\"bhret6\",\"bhret36\",\"noa_a\"],\n",
        "    \"M6\": [\"assetg\",\"bm\",\"me_june\",\"bhret6\",\"bhret36\",\"accruals\"],\n",
        "    \"M7\": [\"assetg\",\"bm\",\"me_june\",\"bhret6\",\"bhret36\",\"syassetg\"]\n",
        "}\n",
        "\n",
        "resultsC = {m: fama_macbeth(dfC, X) for m, X in MODEL_VARS.items()}\n",
        "resultsD = {m: fama_macbeth(dfD, X) for m, X in MODEL_VARS.items()}\n",
        "\n",
        "# ======================================================================\n",
        "# 10. TABLE 출력\n",
        "# ======================================================================\n",
        "TABLE_COLS = [\n",
        "    \"Constant\",\"ASSETG\",\"L2ASSETG\",\"BM\",\"MV\",\n",
        "    \"BHRET6\",\"BHRET36\",\"5YSALESG\",\"CI\",\"NOA/A\",\n",
        "    \"ACCRUALS\",\"5YASSETG\"\n",
        "]\n",
        "\n",
        "VAR_MAP = {\n",
        "    \"const\": \"Constant\",\n",
        "    \"assetg\": \"ASSETG\",\n",
        "    \"l2assetg\": \"L2ASSETG\",\n",
        "    \"bm\": \"BM\",\n",
        "    \"me_june\": \"MV\",\n",
        "    \"bhret6\": \"BHRET6\",\n",
        "    \"bhret36\": \"BHRET36\",\n",
        "    \"sysalesg\": \"5YSALESG\",\n",
        "    \"ci\": \"CI\",\n",
        "    \"noa_a\": \"NOA/A\",\n",
        "    \"accruals\": \"ACCRUALS\",\n",
        "    \"syassetg\": \"5YASSETG\",\n",
        "}\n",
        "\n",
        "def build_two_rows(beta, tval, Xvars):\n",
        "    beta_row = {c: \".\" for c in TABLE_COLS}\n",
        "    t_row    = {c: \".\" for c in TABLE_COLS}\n",
        "\n",
        "    fullvars = [\"const\"] + Xvars\n",
        "    for name, b, t in zip(fullvars, beta, tval):\n",
        "        col = VAR_MAP[name]\n",
        "        if np.isnan(b):\n",
        "            beta_row[col] = \"nan\"\n",
        "            t_row[col]    = \"(nan)\"\n",
        "        else:\n",
        "            beta_row[col] = f\"{b:.6f}\"\n",
        "            t_row[col]    = f\"({t:.2f})\"\n",
        "    return beta_row, t_row\n",
        "\n",
        "# ======================================================================\n",
        "# 11. IMAGE & CSV 저장\n",
        "# ======================================================================\n",
        "def save_table_image(panel_name, results, filename):\n",
        "    header = [\"Model\", \"Type\"] + TABLE_COLS\n",
        "    table_data = []\n",
        "\n",
        "    for i, (m, (beta, tval)) in enumerate(results.items(), start=1):\n",
        "        row_beta, row_t = build_two_rows(beta, tval, MODEL_VARS[m])\n",
        "        table_data.append([str(i), \"Beta\"]   + [row_beta[c] for c in TABLE_COLS])\n",
        "        table_data.append([\"\",      \"t-stat\"]+ [row_t[c]    for c in TABLE_COLS])\n",
        "        table_data.append([\"\"] * len(header))\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(22, len(table_data) * 0.42))\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "    the_table = plt.table(\n",
        "        cellText=[header] + table_data,\n",
        "        cellLoc=\"left\",\n",
        "        loc=\"center\"\n",
        "    )\n",
        "\n",
        "    the_table.auto_set_font_size(False)\n",
        "    the_table.set_fontsize(10)\n",
        "    the_table.scale(1, 1.25)\n",
        "\n",
        "    for j in range(len(header)):\n",
        "        cell = the_table[0, j]\n",
        "        cell.set_facecolor(\"#F0F0F0\")\n",
        "        cell.set_text_props(weight=\"bold\")\n",
        "\n",
        "    for (r, c), cell in the_table.get_celld().items():\n",
        "        cell.set_linewidth(0)\n",
        "\n",
        "    plt.title(panel_name, fontsize=18, fontweight='bold', pad=15)\n",
        "    plt.savefig(filename, dpi=300, bbox_inches=\"tight\")\n",
        "    plt.close()\n",
        "    print(f\"Saved → {filename}\")\n",
        "\n",
        "def save_table_csv(results, filename_csv):\n",
        "    header = [\"Model\", \"Type\"] + TABLE_COLS\n",
        "    rows = []\n",
        "    for i, (m, (beta, tval)) in enumerate(results.items(), start=1):\n",
        "        row_beta, row_t = build_two_rows(beta, tval, MODEL_VARS[m])\n",
        "        rows.append([str(i), \"Beta\"]   + [row_beta[c] for c in TABLE_COLS])\n",
        "        rows.append([\"\",      \"t-stat\"]+ [row_t[c]    for c in TABLE_COLS])\n",
        "    df_out = pd.DataFrame(rows, columns=header)\n",
        "    df_out.to_csv(filename_csv, index=False, encoding=\"utf-8-sig\")\n",
        "    print(f\"Saved CSV → {filename_csv}\")\n",
        "\n",
        "# 전체 기간 Panel C / D 저장\n",
        "save_table_image(\"Panel C. Medium Size Firms (1963–2024)\", resultsC, \"PanelC_Table3_1963_2024.png\")\n",
        "save_table_image(\"Panel D. Large Size Firms (1963–2024)\", resultsD, \"PanelD_Table3_1963_2024.png\")\n",
        "\n",
        "save_table_csv(resultsC, \"PanelC_Table3_1963_2024.csv\")\n",
        "save_table_csv(resultsD, \"PanelD_Table3_1963_2024.csv\")\n",
        "\n",
        "files.download(\"PanelC_Table3_1963_2024.png\")\n",
        "files.download(\"PanelD_Table3_1963_2024.png\")\n",
        "files.download(\"PanelC_Table3_1963_2024.csv\")\n",
        "files.download(\"PanelD_Table3_1963_2024.csv\")\n"
      ]
    }
  ]
}